{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import requests\n",
    "import time\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import datetime as dt\n",
    "from retrying import retry\n",
    "\n",
    "from utils.env import *\n",
    "from utils import avgNav, commonMetric, query, thematicManager as tm, tableManager\n",
    "\n",
    "from oauth2client.service_account import ServiceAccountCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(stop_max_attempt_number=3)\n",
    "def execute_query(sql_query, engine):\n",
    "    return pd.read_sql_query(sql_query, con=engine)\n",
    "\n",
    "\n",
    "def get_adr_stock_ids(ver, cnx):\n",
    "    adr_stock_ids = []\n",
    "    stockinfo_qr = f'''SELECT * FROM `{ver}_stock_infos`'''\n",
    "    stockinfo = pd.read_sql_query(stockinfo_qr, con=cnx)\n",
    "    adr_stock_ids.extend(stockinfo[stockinfo.adr == 1].jittaStockId.to_list())\n",
    "    \n",
    "    return adr_stock_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "import time\n",
    "\n",
    "def create_session_with_retries(retries, backoff_factor, status_forcelist):\n",
    "    session = requests.Session()\n",
    "    retry = Retry(\n",
    "        total=retries,\n",
    "        read=retries,\n",
    "        connect=retries,\n",
    "        backoff_factor=backoff_factor,\n",
    "        status_forcelist=status_forcelist,\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session\n",
    "\n",
    "def sandbox_v2(fid, jid, bid, uid, scope):\n",
    "    url = f\"http://192.168.152.53:3000/api/v2/formulas/{fid}/results\"\n",
    "    params = {\n",
    "        \"jitta_stock_ids\": jid,\n",
    "        \"buildVersionId\": bid,\n",
    "        \"sector\": \"ALL\",\n",
    "        \"industry\": \"ALL\",\n",
    "        \"scopeType\": scope,\n",
    "        \"limit\": \"\",\n",
    "        \"skip\": \"\"\n",
    "    }\n",
    "    headers = {\n",
    "        \"universe-id\": uid\n",
    "    }\n",
    "\n",
    "    retries = 5\n",
    "    backoff_factor = 0.3\n",
    "    status_forcelist = [500, 502, 503, 504]\n",
    "\n",
    "    session = create_session_with_retries(retries, backoff_factor, status_forcelist)\n",
    "\n",
    "    try:\n",
    "        response = session.get(url, params=params, headers=headers, timeout=120)\n",
    "        if response.status_code == 200:\n",
    "            time.sleep(0.5)\n",
    "            data = response.json()\n",
    "            return data\n",
    "        else:\n",
    "            print(\"Failed to retrieve data. Status code:\", response.status_code)\n",
    "            return None\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"The request timed out\")\n",
    "        return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Handle other possible exceptions\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# def sandbox_v2(fid, jid, bid, uid, scope):\n",
    "#     url = f\"http://192.168.152.53:3000/api/v2/formulas/{fid}/results\"\n",
    "#     params = {\n",
    "#         \"jitta_stock_ids\": jid,\n",
    "#         \"buildVersionId\": bid,\n",
    "#         \"sector\": \"ALL\",\n",
    "#         \"industry\": \"ALL\",\n",
    "#         \"scopeType\": scope,\n",
    "#         \"limit\": \"\",\n",
    "#         \"skip\": \"\"\n",
    "#     }\n",
    "#     headers = {\n",
    "#         \"universe-id\": uid\n",
    "#     }\n",
    "\n",
    "#     response = requests.get(url, params=params, headers=headers, timeout=120)\n",
    "\n",
    "#     if response.status_code == 200:\n",
    "#         time.sleep(1)\n",
    "#         data = response.json()\n",
    "#         return data\n",
    "#     else:\n",
    "#         print(\"Failed to retrieve data. Status code:\", response.status_code)\n",
    "#         return None\n",
    "    \n",
    "\n",
    "def rolling_quantile(df, column, quantile, window_size):\n",
    "    expanding_window_quantile = df[column].expanding(min_periods=1).quantile(quantile)\n",
    "    rolling_window_quantile = df[column].rolling(window=window_size, min_periods=window_size).quantile(quantile)\n",
    "    return expanding_window_quantile.combine_first(rolling_window_quantile)\n",
    "\n",
    "\n",
    "def get_clean_jitta_stock_ids(jitta_score_date_like, list_adr, list_etf, skip_jid, cnx, ver):\n",
    "    clean_jitta_stock_ids_dict = {}\n",
    "    \n",
    "    for i, date in enumerate(jitta_score_date_like):\n",
    "        if len(list_adr) == 1:\n",
    "            top_jitta_score_qr = f'''\n",
    "                SELECT * FROM `{ver}_jitta_score_price$monthly$1_Bh-KI69fC`\n",
    "                WHERE seen LIKE '{date}'\n",
    "                AND `jittaStockId` NOT IN {tuple(list_etf)}\n",
    "                AND `jittaStockId` NOT IN {tuple(skip_jid)}\n",
    "                AND `jittaStockId` !=  {list_adr[0]}\n",
    "                ORDER BY `value` DESC\n",
    "                LIMIT 200;\n",
    "                '''\n",
    "        elif len(list_adr) == 0:\n",
    "            top_jitta_score_qr = f'''\n",
    "                SELECT * FROM `{ver}_jitta_score_price$monthly$1_Bh-KI69fC`\n",
    "                WHERE seen LIKE '{date}'\n",
    "                AND `jittaStockId` NOT IN {tuple(list_etf)}\n",
    "                AND `jittaStockId` NOT IN {tuple(skip_jid)}\n",
    "                ORDER BY `value` DESC\n",
    "                LIMIT 200;\n",
    "                '''\n",
    "        else:\n",
    "            top_jitta_score_qr = f'''\n",
    "                SELECT * FROM `{ver}_jitta_score_price$monthly$1_Bh-KI69fC`\n",
    "                WHERE seen LIKE '{date}'\n",
    "                AND `jittaStockId` NOT IN {tuple(list_etf)}\n",
    "                AND `jittaStockId` NOT IN {tuple(skip_jid)}\n",
    "                AND `jittaStockId` NOT IN {tuple(list_adr)}\n",
    "                ORDER BY `value` DESC\n",
    "                LIMIT 200;\n",
    "                '''\n",
    "\n",
    "        df = pd.read_sql_query(top_jitta_score_qr, con=cnx)\n",
    "        df.seen = pd.to_datetime(df.seen)\n",
    "        latest_seen_df = df.loc[df.groupby('jittaStockId')['seen'].idxmax()]\n",
    "        latest_seen_df_sorted = latest_seen_df.sort_values(by='value', ascending=False)[:50]\n",
    "\n",
    "        # result = result[result.value > 7] # filter score > 7\n",
    "        # display(latest_seen_df_sorted)\n",
    "        \n",
    "        jitta_stock_ids = latest_seen_df_sorted.jittaStockId.to_list()\n",
    "        clean_jitta_stock_ids = [id for id in jitta_stock_ids]\n",
    "        \n",
    "        # Appending to the dictionary\n",
    "        clean_jitta_stock_ids_dict[date] = clean_jitta_stock_ids\n",
    "    \n",
    "    return clean_jitta_stock_ids_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computer_each_dataversion(clean_jitta_stock_ids_dict, ver, fid, bid, scope):\n",
    "    cache = {}\n",
    "    pe_zone = {}\n",
    "    \n",
    "    for date in clean_jitta_stock_ids_dict.keys():\n",
    "        top50_each_date = clean_jitta_stock_ids_dict[str(date)]\n",
    "        list_pe_catagory2 = []\n",
    "        \n",
    "        if len(top50_each_date) == 0:\n",
    "            # list_pe_catagory2 = [np.nan] * 50\n",
    "            continue\n",
    "        \n",
    "        for stock_id in tqdm(top50_each_date):\n",
    "            if stock_id in cache:\n",
    "                df1 = cache[stock_id]\n",
    "                SKIP = True\n",
    "            else:\n",
    "                SKIP = False\n",
    "                \n",
    "            if not SKIP:\n",
    "                resp = sandbox_v2(fid=fid, jid=stock_id, bid=bid, uid=ver, scope=scope)\n",
    "                value = resp['data'][0]['value']\n",
    "                \n",
    "                pe_df = pd.DataFrame(value)\n",
    "                pe_df.set_index('seen', inplace=True)\n",
    "                pe_df = pe_df[~pe_df.index.duplicated(keep='last')]  \n",
    "                pe_df.index = pd.to_datetime(pe_df.index)\n",
    "                pe_df = pe_df.resample('M').last()\n",
    "                \n",
    "                # PE Calculation\n",
    "                df1 = pe_df[['v']].copy()\n",
    "                df1.drop(df1[df1['v'] == \"N/A\"].index, inplace=True)\n",
    "                df1.dropna(inplace=True)\n",
    "                df1 = df1.astype(float)\n",
    "                df1['jitta_stock_id'] = stock_id\n",
    "                \n",
    "                df1['rolling_10th'] = rolling_quantile(df1, 'v', 0.1, 10*12)\n",
    "                df1['rolling_20th'] = rolling_quantile(df1, 'v', 0.2, 10*12)\n",
    "                df1['rolling_30th'] = rolling_quantile(df1, 'v', 0.3, 10*12)\n",
    "                df1['rolling_40th'] = rolling_quantile(df1, 'v', 0.4, 10*12)\n",
    "                df1['rolling_50th'] = rolling_quantile(df1, 'v', 0.5, 10*12)\n",
    "                df1['rolling_60th'] = rolling_quantile(df1, 'v', 0.6, 10*12)\n",
    "                df1['rolling_70th'] = rolling_quantile(df1, 'v', 0.7, 10*12)\n",
    "                df1['rolling_80th'] = rolling_quantile(df1, 'v', 0.8, 10*12)\n",
    "                df1['rolling_90th'] = rolling_quantile(df1, 'v', 0.9, 10*12)\n",
    "\n",
    "                df1['PE_category2'] = np.where(df1['v'] < df1['rolling_10th'], '0_10',\n",
    "                                                    np.where((df1['v'] >= df1['rolling_10th']) & (df1['v'] < df1['rolling_20th']), '10_20',\n",
    "                                                    np.where((df1['v'] >= df1['rolling_20th']) & (df1['v'] < df1['rolling_30th']), '20_30',\n",
    "                                                    np.where((df1['v'] >= df1['rolling_30th']) & (df1['v'] < df1['rolling_40th']), '30_40',\n",
    "                                                    np.where((df1['v'] >= df1['rolling_40th']) & (df1['v'] < df1['rolling_50th']), '40_50',\n",
    "                                                    np.where((df1['v'] >= df1['rolling_50th']) & (df1['v'] < df1['rolling_60th']), '50_60',\n",
    "                                                    np.where((df1['v'] >= df1['rolling_60th']) & (df1['v'] < df1['rolling_70th']), '60_70',\n",
    "                                                    np.where((df1['v'] >= df1['rolling_70th']) & (df1['v'] < df1['rolling_80th']), '70_80',\n",
    "                                                    np.where((df1['v'] >= df1['rolling_80th']) & (df1['v'] < df1['rolling_90th']), '80_90',\n",
    "                                                    np.where((df1['v'] >= df1['rolling_90th']), '90+', 'Unknown'))))))))))\n",
    "\n",
    "                df1.index = pd.to_datetime(df1.index) \n",
    "                \n",
    "                cache[stock_id] = df1\n",
    "                # display(df1)\n",
    "\n",
    "            try:\n",
    "                # print(date)\n",
    "                pe_category_value2 = df1.loc[(df1.index.year == int(date[:4])) & \n",
    "                                             (df1.index.month == int(date[5:7])), 'PE_category2'].values[-1]\n",
    "                # pe_v = df1.loc[(df1.index.year == int(date[:4])) & \n",
    "                #                              (df1.index.month == int(date[5:7])), 'v'].values[-1]\n",
    "                list_pe_catagory2.append(pe_category_value2)\n",
    "            except Exception as e:\n",
    "                # print(stock_id, e)   \n",
    "                list_pe_catagory2.append(np.nan)  \n",
    "        \n",
    "        \n",
    "        # Calculate how many NaN values are needed\n",
    "        num_nans_to_append = 50 - len(list_pe_catagory2)\n",
    "        # Append NaN values if needed\n",
    "        if num_nans_to_append > 0:\n",
    "            list_pe_catagory2.extend([np.nan] * num_nans_to_append)\n",
    "        pe_zone[date] = list_pe_catagory2      \n",
    "            \n",
    "    return pe_zone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_pe_zone(pe_zone):\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(pe_zone)\n",
    "\n",
    "    # Count occurrences of each value\n",
    "    value_counts_df = df.apply(pd.Series.value_counts)\n",
    "\n",
    "    # Reindex to ensure all categories are present\n",
    "    index_categories = ['0_10', '10_20', '20_30', '30_40', '40_50', '50_60', '60_70', '70_80', '80_90', '90+']\n",
    "    value_counts_df = value_counts_df.reindex(index_categories)\n",
    "\n",
    "    # Display the transposed DataFrame for better readability\n",
    "    display(value_counts_df.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dataversion = [\n",
    "                # 'US_2024-05-31',\n",
    "                # 'HK_2024-05-31',\n",
    "                # 'CN_2024-05-31',\n",
    "                'TH_2024-06-20',\n",
    "                # 'JP_2024-05-31',\n",
    "                # # 'VN_2024-05-01',\n",
    "                \n",
    "                # 'UK_2024-05-31',\n",
    "                # 'IN_2024-01-03',\n",
    "                # 'KR_2024-01-03',\n",
    "                # 'TW_2024-01-03',\n",
    "                # 'SG_2024-06-11',\n",
    "                # 'DE_2024-06-12',/\n",
    "                # 'AU_2024-06-11',\n",
    "                # 'CA_2024-01-03',\n",
    "                ]\n",
    "\n",
    "jitta_score_date_like = [\n",
    "\n",
    "                    # '2012-12-%%',\n",
    "                    # '2013-12-%%',\n",
    "                    # '2014-12-%%',\n",
    "                    # '2015-12-%%',\n",
    "                    # '2016-12-%%',\n",
    "                    # '2017-12-%%',\n",
    "                    # '2018-12-%%',\n",
    "                    # '2019-12-%%',\n",
    "                    # '2020-12-%%',\n",
    "                    # '2021-12-%%',\n",
    "                    # '2022-12-%%',\n",
    "                    # '2023-12-%%',\n",
    "                    \n",
    "\n",
    "                    '2024-01-%%',\n",
    "                    '2024-02-%%',\n",
    "                    '2024-03-%%',\n",
    "                    '2024-04-%%',\n",
    "                    '2024-05-%%',\n",
    "                    '2024-06-%%',\n",
    "                    ]\n",
    "\n",
    "# skip_jid\n",
    "skip_jid = [8173, 2604908, 2259841, 2583555, 2259840, 2259842, 2259843, 2578562, 2573968, 2574007, 2604908]\n",
    "# list_etf\n",
    "etf_df = pd.read_json(\"etf.json\", orient='records')\n",
    "list_etf = pd.DataFrame.from_records(etf_df['US']).jitta_stock_id.to_list()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pd.set_option('display.max_rows', None)\n",
    "\n",
    "# fid, bid, scope = '6633b62594330887b8ec65cb', 'PytXziitn', 'monthly'\n",
    "# # fid, bid, scope = '664a20726101425826b0a517', 'HwSIpqwiT', 'monthly'  # pe30\n",
    "# # fid, bid, scope = '664e1b8d6101425826b14a55', 'iRBkTTRDJ', 'monthly' \n",
    "# ver = 'US_2024-05-01'\n",
    "# stock_id = 2577393\n",
    "\n",
    "# resp = sandbox_v2(fid=fid, jid=stock_id, bid=bid, uid=ver, scope=scope)\n",
    "# value = resp['data'][0]['value']\n",
    "# pe_df = pd.DataFrame(value)\n",
    "# pe_df.set_index('seen', inplace=True)\n",
    "# pe_df = pe_df[~pe_df.index.duplicated(keep='last')]  \n",
    "# # Resample by month and keep the last entry of each month\n",
    "# pe_df.index = pd.to_datetime(pe_df.index)\n",
    "# last_entries = pe_df.resample('M').last()\n",
    "\n",
    "# pe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PE Calculation\n",
    "# df1 = pe_df[['v']].copy()\n",
    "# df1.drop(df1[df1['v'] == \"N/A\"].index, inplace=True)\n",
    "# df1.dropna(inplace=True)\n",
    "# df1 = df1.astype(float)\n",
    "\n",
    "# df1['rolling_10th'] = rolling_quantile(df1, 'v', 0.1, 10*12)\n",
    "# df1['rolling_20th'] = rolling_quantile(df1, 'v', 0.2, 10*12)\n",
    "# df1['rolling_30th'] = rolling_quantile(df1, 'v', 0.3, 10*12)\n",
    "# df1['rolling_40th'] = rolling_quantile(df1, 'v', 0.4, 10*12)\n",
    "# df1['rolling_50th'] = rolling_quantile(df1, 'v', 0.5, 10*12)\n",
    "# df1['rolling_60th'] = rolling_quantile(df1, 'v', 0.6, 10*12)\n",
    "# df1['rolling_70th'] = rolling_quantile(df1, 'v', 0.7, 10*12)\n",
    "# df1['rolling_80th'] = rolling_quantile(df1, 'v', 0.8, 10*12)\n",
    "# df1['rolling_90th'] = rolling_quantile(df1, 'v', 0.9, 10*12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TH_2024-06-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:07<00:00,  1.36s/it]\n",
      "100%|██████████| 50/50 [00:23<00:00,  2.15it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 2821.98it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 3025.01it/s]\n",
      "100%|██████████| 50/50 [00:18<00:00,  2.68it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 3146.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_10</th>\n",
       "      <th>10_20</th>\n",
       "      <th>20_30</th>\n",
       "      <th>30_40</th>\n",
       "      <th>40_50</th>\n",
       "      <th>50_60</th>\n",
       "      <th>60_70</th>\n",
       "      <th>70_80</th>\n",
       "      <th>80_90</th>\n",
       "      <th>90+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-%%</th>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-%%</th>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-%%</th>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-%%</th>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-%%</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-%%</th>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0_10  10_20  20_30  30_40  40_50  50_60  60_70  70_80  80_90  90+\n",
       "2024-01-%%  14.0   13.0    1.0    2.0    4.0    6.0    2.0    4.0    4.0  NaN\n",
       "2024-02-%%  18.0   10.0    3.0    4.0    3.0    4.0    3.0    1.0    3.0  1.0\n",
       "2024-03-%%  18.0   13.0    1.0    4.0    3.0    4.0    3.0    3.0    1.0  NaN\n",
       "2024-04-%%  18.0    9.0    3.0    6.0    1.0    7.0    2.0    NaN    3.0  1.0\n",
       "2024-05-%%  22.0    7.0    2.0    7.0    3.0    2.0    4.0    2.0    1.0  NaN\n",
       "2024-06-%%  26.0    3.0    3.0    6.0    5.0    2.0    2.0    2.0    1.0  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    for dataversion in list_dataversion:\n",
    "        print(dataversion)\n",
    "        list_adr = get_adr_stock_ids(dataversion, cnx)\n",
    "        clean_jitta_stock_ids_dict = get_clean_jitta_stock_ids(jitta_score_date_like, list_adr, list_etf, skip_jid, cnx, ver=dataversion)\n",
    "        pe_decile = computer_each_dataversion(clean_jitta_stock_ids_dict, dataversion, fid, bid, scope)\n",
    "        display_pe_zone(pe_decile)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    fid, bid, scope = '6633b62594330887b8ec65cb', '1NCMPuCYt', 'monthly' # pe6\n",
    "    # fid, bid, scope = '65dff500faa2180026d60183', 'MRrX47PTp', 'monthly' # pe5\n",
    "\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "market_valuation-IvGVmgtZ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
